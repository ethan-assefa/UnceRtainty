knitr::opts_chunk$set(echo = TRUE)
library(devtools)
library(roxygen2)
setwd("C:/Users/affes/OneDrive/Documents/UVA SDS Fall 2023/DS 6030/UnceRtainty")
# this function generates documentation based on the in-code comments above
roxygen2::roxygenise()
setwd("C:/Users/affes/OneDrive/Documents/UVA SDS Fall 2023/DS 6030/UnceRtainty")
# this function generates documentation based on the in-code comments above
roxygen2::roxygenise()
devtools::document()
round(0.6)
round(0.55)
round(0.45)
# this function generates documentation based on the in-code comments above
devtools::document()
setwd("C:/Users/affes/OneDrive/Documents/UVA SDS Fall 2023/DS 6030/UnceRtainty")
# this function generates documentation based on the in-code comments above
devtools::document()
setwd("C:/Users/affes/OneDrive/Documents/UVA SDS Fall 2023/DS 6030/UnceRtainty")
# this function generates documentation based on the in-code comments above
devtools::document()
setwd("C:/Users/affes/OneDrive/Documents/UVA SDS Fall 2023/DS 6030/UnceRtainty")
# this function generates documentation based on the in-code comments above
devtools::document()
devtools::load_all()
# this function generates documentation based on the in-code comments above
devtools::document()
# this function generates documentation based on the in-code comments above
devtools::document()
devtools::use_package('dplyr')
devtools::use_package('pROC')
library(devtools)
devtools::use_package('pROC')
package.name <- "UnceRtainty"
package.dir <- paste("C:/Users/affes/OneDrive/Documents/UVA SDS Fall 2023/DS 6030/",package.name,sep="")
setwd(package.dir)
### --- Use Roxygenise to generate .RD files from my comments
library(roxygen2)
roxygenise(package.dir=package.dir)
system(command=paste("R CMD INSTALL '",package.dir,"'",sep=""))
library(UnceRtainty)
library(UnceRtainty)
library(UnceRtainty)
train <- mtcars[1:16,]
test_x <- mtcars[17:32,-9]
obs <- mtcars[17:32,9]
example_log_model <- glm(am ~ qsec + wt + gear, data = train, family = "binomial")
test_log <- MakePredictions(model=example_log_model, test_data=test_x, observed_outcome=obs)
MakePredictions(test_log)
calculate_classification_metrics(test_log)
calculate_EPE(test_log)
calculate_misclassification_cost(test_log)
calculate_misclassification_cost(test_log, 3, 2)
confusion_matrix_metrics_plot(test_log)
find_optimal_threshold(test_log)
generate_confusion_matrix_visualization(test_log)
generate_roc(test_log)
generate_roc_curve_visualization(test_log)
confusion_matrix_metrics_plot(test_log)
find_optimal_threshold(test_log)
generate_confusion_matrix_visualization(test_log)
generate_roc(test_log)
generate_roc_curve_visualization(test_log)
set_cost()
set_cost(test_log)
set_cost(test_log, 3, 4)
confusion_matrix_metrics_plot(test_log)
find_optimal_threshold(test_log)
generate_confusion_matrix_visualization(test_log)
generate_roc(test_log)
generate_roc_curve_visualization(test_log)
remove.packages("UnceRtainty")
library(UnceRtainty)
train <- mtcars[1:16,]
test_x <- mtcars[17:32,-9]
obs <- mtcars[17:32,9]
example_log_model <- glm(am ~ qsec + wt + gear, data = train, family = "binomial")
test_log <- MakePredictions(model=example_log_model, test_data=test_x, observed_outcome=obs)
calculate_classification_metrics(test_log)
calculate_EPE(test_log)
calculate_misclassification_cost(test_log, 3, 2)
confusion_matrix_metrics_plot(test_log)
find_optimal_threshold(test_log)
generate_confusion_matrix_visualization(test_log)
generate_roc(test_log)
generate_roc_curve_visualization(test_log)
generate_confusion_matrix_visualization(test_log)
calculate_classification_metrics(test_log)
calculate_EPE(test_log)
calculate_misclassification_cost(test_log, 3, 2)
confusion_matrix_metrics_plot(test_log)
find_optimal_threshold(test_log)
generate_confusion_matrix_visualization(test_log)
remove.packages("UnceRtainty")
library(UnceRtainty)
train <- mtcars[1:16,]
test_x <- mtcars[17:32,-9]
obs <- mtcars[17:32,9]
example_log_model <- glm(am ~ qsec + wt + gear, data = train, family = "binomial")
test_log <- MakePredictions(model=example_log_model, test_data=test_x, observed_outcome=obs)
calculate_classification_metrics(test_log)
calculate_EPE(test_log)
calculate_misclassification_cost(test_log, 3, 2)
confusion_matrix_metrics_plot(test_log)
find_optimal_threshold(test_log)
generate_confusion_matrix_visualization(test_log)
generate_roc(test_log)
generate_roc_curve_visualization(test_log)
set_cost(test_log, 3, 4)
generate_roc(test_log)
generate_roc_curve_visualization(test_log)
calculate_classification_metrics(test_log)
calculate_EPE(test_log)
calculate_classification_metrics(test_log)
calculate_EPE(test_log)
calculate_misclassification_cost(test_log, 3, 2)
confusion_matrix_metrics_plot(test_log)
find_optimal_threshold(test_log)
generate_confusion_matrix_visualization(test_log)
generate_roc(test_log)
generate_roc_curve_visualization(test_log)
test_log$predictions
test_log$observed_outcomes
generate_roc_curve_visualization <- function(unceRtain_object){
library(pROC)
library(ROCR)
library(ggplot2)
true_labels <- unceRtain_object$observed_outcome
predicted_probabilities <- round(unceRtain_object$predictions)
roc_obj <- roc(true_labels, predicted_probabilities)
auc_value = auc(roc_obj)
cat("AUC quantifies the overall performance of the model across all possible thresholds. Higher AUC values indicate better discrimination ability, but the choice of the optimal threshold depends on the application's context.\n")
cat("The ROC curve is a graphical representation of a model's performance across various classification thresholds.\n")
cat("It illustrates the trade-off between the true positive rate (sensitivity) and the false positive rate (1-specificity) at different threshold values.\n\n")
# Visualization
plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_value, 2), ")"))
}
generate_roc_curve_visualization(test_log)
calculate_classification_metrics(test_log)
calculate_EPE(test_log)
calculate_misclassification_cost(test_log, 3, 2)
confusion_matrix_metrics_plot(test_log)
find_optimal_threshold(test_log)
generate_confusion_matrix_visualization(test_log)
generate_roc(test_log)
generate_roc_curve_visualization(test_log)
remove.packages("UnceRtainty")
train <- mtcars[1:16,]
test_x <- mtcars[17:32,-9]
obs <- mtcars[17:32,9]
example_log_model <- glm(am ~ qsec + wt + gear, data = train, family = "binomial")
test_log <- MakePredictions(model=example_log_model, test_data=test_x, observed_outcome=obs)
calculate_classification_metrics(test_log)
calculate_EPE(test_log)
calculate_misclassification_cost(test_log, 3, 2)
confusion_matrix_metrics_plot(test_log)
find_optimal_threshold(test_log)
generate_confusion_matrix_visualization(test_log)
generate_roc(test_log)
generate_roc_curve_visualization(test_log)
set_cost(test_log, 3, 4)
set_cost(test_log, 3, 40)
set_cost(test_log, 33, 40)
